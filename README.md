# ğŸš€ High-Performance Image Processing

## A Parallel Computing Benchmark Study

A comprehensive and reproducible performance comparison of **parallel computing architectures** for **high-resolution image processing**. This project evaluates how different parallelization strategies scale on real-world, computation-heavy workloads.

---

## ğŸ¯ Project Overview

Modern image processing pipelines must handle extremely large images (up to **46+ megapixels**) with strict performance requirements. This study systematically compares four parallel computing architectures by implementing **identical algorithms** across each paradigm and benchmarking their performance.

> **Research Question**
> **Which parallel architecture delivers optimal performance for highâ€‘resolution image processing?**

The results provide **empirical evidence**, **clear performance trade-offs**, and **practical guidance** for choosing the right architecture.

---

## ğŸ”¬ Research Methodology

### Parallel Architectures Evaluated

| Architecture   | Paradigm    | Approach                            |
| -------------- | ----------- | ----------------------------------- |
| **Sequential** | SISD        | Single-threaded baseline            |
| **OpenMP**     | MIMD        | Multi-core CPU parallelization      |
| **CUDA**       | SIMD        | GPU-accelerated massive parallelism |
| **Hybrid**     | MIMD + SIMD | Optimized CPUâ€“GPU pipeline          |

### Image Processing Operations

The following widely-used and computationally intensive operations were implemented:

* ğŸ”² **Gaussian Blur** â€“ Convolution-based smoothing (most compute-intensive)
* ğŸ” **Sobel Edge Detection** â€“ Gradient-based edge extraction
* ğŸ¨ **RGB to Grayscale Conversion** â€“ Color space transformation

These operations represent common stages in real-world image processing workflows.

---

## ğŸ§ª Benchmark Framework

Benchmarking follows **Rodinia Benchmark Suite** principles to ensure fairness and reproducibility:

* âœ… **DIV2K dataset** (42â€“46 MP images)
* âœ… **Five test images** (0801â€“0805)
* âœ… **5 iterations per test** (averaged results)
* âœ… **Kernel execution time measured separately** from I/O
* âœ… **Identical output validation** across all implementations

**Metrics Collected**:

* Kernel execution time
* I/O overhead
* Total pipeline time
* Relative speedup

---

## ğŸ“Š Key Results

### â±ï¸ Average Kernel Execution Time

| Architecture     | Avg. Time      |
| ---------------- | -------------- |
| Sequential       | ~128 ms        |
| OpenMP (8 cores) | ~102 ms        |
| CUDA             | ~4 ms          |
| **Hybrid**       | **~3.5 ms** ğŸ† |

â¡ï¸ **Up to 49Ã— speedup** over sequential execution.

---

### âš¡ Speedup by Image

| Image | Resolution | OpenMP | CUDA  | Hybrid    |
| ----- | ---------- | ------ | ----- | --------- |
| 0801  | 7952Ã—5304  | 1.18Ã—  | 31.7Ã— | 37.4Ã—     |
| 0802  | 7968Ã—5312  | 1.19Ã—  | 35.3Ã— | **49.2Ã—** |
| 0803  | 7952Ã—5304  | 1.27Ã—  | 19.4Ã— | 39.9Ã—     |
| 0804  | 7952Ã—5304  | 1.22Ã—  | 46.0Ã— | 32.8Ã—     |
| 0805  | 7968Ã—5312  | 1.36Ã—  | 36.1Ã— | 41.5Ã—     |

> All values represent **kernel execution time speedup**.

---

## ğŸ§  Operation-Level Performance

### Gaussian Blur (Most Intensive)

* Sequential: **117.5 ms**
* OpenMP: **69.7 ms** (1.68Ã—)
* CUDA: **3.8 ms** (30.9Ã—)
* **Hybrid: 2.5 ms (47.0Ã—)** ğŸ†

### Sobel Edge Detection

* Sequential: **9.0 ms**
* OpenMP: **19.9 ms** (slower due to overhead)
* **CUDA: 0.2 ms (45.0Ã—)** ğŸ†
* Hybrid: **0.7 ms (12.9Ã—)**

### RGB to Grayscale (Lightweight)

* Sequential: **5.1 ms**
* OpenMP: **16.0 ms** (overhead dominates)
* CUDA: **0.2 ms (25.5Ã—)**
* **Hybrid: <0.1 ms (>50Ã—)** ğŸ†

---

## ğŸ” Critical Insights

### ğŸš€ GPU Dominance

* CUDA and Hybrid achieve **30â€“50Ã— speedup**
* OpenMP shows limited benefit for GPU-friendly workloads
* For simple operations, CPU threading overhead can exceed gains

### ğŸ§© Hybrid Advantage

* Best performance for **heavy computations** (Gaussian Blur)
* Asynchronous execution and optimized memory usage
* Reduced latency via CPUâ€“GPU cooperation

### ğŸ§  Operation Complexity Matters

* **Complex** â†’ Hybrid
* **Medium** â†’ CUDA
* **Simple** â†’ GPU approaches still win
* OpenMP struggles with overhead

### ğŸ–¼ï¸ Image Characteristics Matter

* Speedup varies from **32Ã— to 49Ã—**
* Image size and structure affect performance
* Multi-image benchmarking is essential

### âš–ï¸ Kernel vs End-to-End

* Kernel-only benchmarks show GPU strength
* Real systems must consider I/O costs

---

## ğŸ› ï¸ Technologies Used

### Core Stack

* **CUDA Toolkit 12+**
* **OpenMP 5+**
* **C++17**
* **BMP Image Format**

### Environment

* **WSL (Windows Subsystem for Linux)**
* **NVIDIA GPU (CC â‰¥ 6.0)**
* **ImageMagick**
* **DIV2K Dataset**

### Analysis Tools

* **Rodinia Benchmark Framework**
* **Python + Matplotlib**
* Custom timing utilities
* Statistical averaging (5 runs)

---

## ğŸ¯ Project Outcomes

* âœ… Up to **49Ã— performance improvement**
* âœ… Hybrid architecture validated as best overall
* âœ… Reproducible and standardized benchmarking
* âœ… Clear architectural decision guidelines
* âœ… Strong educational and research value

---

## ğŸ’¡ Practical Applications

* Real-time video processing
* Medical imaging systems
* Autonomous vision pipelines
* Scientific image analysis
* High-resolution media production

---

## ğŸ“Œ Architecture Selection Guide

### Sequential

* âŒ Not suitable for production
* âœ… Baseline and validation

### OpenMP

* âš ï¸ Limited gains
* âœ… Irregular or memory-bound tasks

### CUDA

* âœ… Excellent for most image processing
* âš ï¸ Requires careful memory management

### Hybrid

* ğŸ† Best for heavy workloads
* ğŸ† Maximum performance with optimization

---

## ğŸŒŸ Key Takeaways

* GPU acceleration enables **dramatic performance gains**
* Hybrid CPUâ€“GPU pipelines offer **20â€“30% improvement** over CUDA
* No single architecture fits all workloads
* Benchmarking methodology matters as much as raw speed

---

ğŸ“ˆ *This project bridges theory and practice, proving that informed architectural choices can unlock massive performance improvements in modern image processing.*
